{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88692b0b",
   "metadata": {},
   "source": [
    "# Importamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28b92cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos train.csv y test.csv...\n",
      "Datos cargados correctamente.\n",
      "\n",
      "Primeras 5 filas de df_entrenamiento_bruto:\n",
      "      id            timestamp modo_operacion operador  temperatura    presion  \\\n",
      "0  15000  2021-04-24 03:00:00  mantenimiento      NaN    20.428941  58.474497   \n",
      "1  15001  2020-09-26 19:00:00  mantenimiento        E     1.332931  84.784184   \n",
      "2  15002  2021-07-02 15:00:00           auto        D    17.501579  65.057682   \n",
      "3  15003  2020-02-05 22:00:00           auto      NaN     8.118801  70.127615   \n",
      "4  15004  2020-09-05 18:00:00         manual      NaN    -0.353122  90.738090   \n",
      "\n",
      "   sensor_ruido   sensor_3  fallo  \n",
      "0      0.349400  18.301299      0  \n",
      "1     -2.252684   7.295245      0  \n",
      "2      0.359853  34.271305      0  \n",
      "3      0.489166  -3.748938      0  \n",
      "4     -1.505866  10.157637      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import category_encoders as ce # Para Target Encoding si se usa\n",
    "import itertools # Para generar combinaciones de características\n",
    "import warnings\n",
    "\n",
    "# Ignorar warnings para mantener la salida limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar datos\n",
    "print(\"Cargando datos train.csv y test.csv...\")\n",
    "try:\n",
    "    df_entrenamiento_bruto = pd.read_csv('train.csv')\n",
    "    df_prueba_bruto = pd.read_csv('test.csv')\n",
    "    print(\"Datos cargados correctamente.\")\n",
    "    print(\"\\nPrimeras 5 filas de df_entrenamiento_bruto:\")\n",
    "    print(df_entrenamiento_bruto.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Asegúrate de que 'train.csv' y 'test.csv' estén en el directorio correcto.\")\n",
    "    df_entrenamiento_bruto = pd.DataFrame() \n",
    "    df_prueba_bruto = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a89dc438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Variables Globales Definidas ---\n",
      "  Objetivo: fallo\n",
      "  Características numéricas base: ['temperatura', 'presion', 'sensor_ruido', 'sensor_3']\n",
      "  Características categóricas: ['modo_operacion', 'operador']\n",
      "  Columna ID a eliminar: id\n",
      "  Columna Timestamp a procesar: timestamp\n",
      "\n",
      "NaNs en df_entrenamiento_bruto:\n",
      "id                   0\n",
      "timestamp            0\n",
      "modo_operacion       0\n",
      "operador          2731\n",
      "temperatura          0\n",
      "presion            625\n",
      "sensor_ruido         0\n",
      "sensor_3             0\n",
      "fallo                0\n",
      "dtype: int64\n",
      "\n",
      "NaNs en df_prueba_bruto:\n",
      "id                   0\n",
      "timestamp            0\n",
      "modo_operacion       0\n",
      "operador          2700\n",
      "temperatura          0\n",
      "presion            625\n",
      "sensor_ruido         0\n",
      "sensor_3             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "objetivo = 'fallo'\n",
    "\n",
    "columnas_numericas_base = ['temperatura', 'presion', 'sensor_ruido', 'sensor_3']\n",
    "columnas_categoricas = ['modo_operacion', 'operador'] \n",
    "columna_id = 'id' # Estan aparte para poder tratarlas ahora\n",
    "columna_timestamp = 'timestamp'\n",
    "\n",
    "print(\"--- Variables Globales Definidas ---\")\n",
    "print(f\"  Objetivo: {objetivo}\")\n",
    "print(f\"  Características numéricas base: {columnas_numericas_base}\")\n",
    "print(f\"  Características categóricas: {columnas_categoricas}\")\n",
    "print(f\"  Columna ID a eliminar: {columna_id}\")\n",
    "print(f\"  Columna Timestamp a procesar: {columna_timestamp}\")\n",
    "\n",
    "# Mostrar NaNs\n",
    "print(\"\\nNaNs en df_entrenamiento_bruto:\")\n",
    "print(df_entrenamiento_bruto.isnull().sum())\n",
    "print(\"\\nNaNs en df_prueba_bruto:\")\n",
    "print(df_prueba_bruto.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec400d",
   "metadata": {},
   "source": [
    "# Preparamos Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53db7b",
   "metadata": {},
   "source": [
    "## Columnas id y TimeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10a65e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Eliminando 'id' de df_entrenamiento.\n",
      "  Eliminando 'id' de df_prueba.\n",
      "\n",
      "Nuevas características de tiempo generadas: ['hora', 'dia_semana', 'mes', 'dia_del_anio', 'es_fin_de_semana']\n",
      "Todas las características numéricas para imputación serán: ['temperatura', 'presion', 'sensor_ruido', 'sensor_3', 'hora', 'dia_semana', 'mes', 'dia_del_anio', 'es_fin_de_semana']\n",
      "  modo_operacion operador  temperatura    presion  sensor_ruido   sensor_3  \\\n",
      "0  mantenimiento      NaN    20.428941  58.474497      0.349400  18.301299   \n",
      "1  mantenimiento        E     1.332931  84.784184     -2.252684   7.295245   \n",
      "2           auto        D    17.501579  65.057682      0.359853  34.271305   \n",
      "3           auto      NaN     8.118801  70.127615      0.489166  -3.748938   \n",
      "4         manual      NaN    -0.353122  90.738090     -1.505866  10.157637   \n",
      "\n",
      "   fallo  hora  dia_semana  mes  dia_del_anio  es_fin_de_semana  \n",
      "0      0     3           5    4           114                 1  \n",
      "1      0    19           5    9           270                 1  \n",
      "2      0    15           4    7           183                 0  \n",
      "3      0    22           2    2            36                 0  \n",
      "4      0    18           5    9           249                 1  \n"
     ]
    }
   ],
   "source": [
    "# Crear copias de trabajo\n",
    "df_entrenamiento = df_entrenamiento_bruto.copy()\n",
    "df_prueba = df_prueba_bruto.copy()\n",
    "\n",
    "print(f\"  Eliminando '{columna_id}' de df_entrenamiento.\")\n",
    "df_entrenamiento = df_entrenamiento.drop(columns=[columna_id])\n",
    "print(f\"  Eliminando '{columna_id}' de df_prueba.\")\n",
    "df_prueba = df_prueba.drop(columns=[columna_id])\n",
    "\n",
    "\n",
    "def dividirTimeStamp(df, nombre_columna):    \n",
    "    df[nombre_columna] = pd.to_datetime(df[nombre_columna])\n",
    "\n",
    "    df['hora'] = df[nombre_columna].dt.hour\n",
    "    df['dia_semana'] = df[nombre_columna].dt.dayofweek # Lunes=0, Domingo=6\n",
    "    df['mes'] = df[nombre_columna].dt.month\n",
    "    df['dia_del_anio'] = df[nombre_columna].dt.dayofyear\n",
    "    df['es_fin_de_semana'] = (df[nombre_columna].dt.dayofweek >= 5).astype(int) \n",
    "    \n",
    "    caracteristicas_generadas = ['hora', 'dia_semana', 'mes', 'dia_del_anio', 'es_fin_de_semana']\n",
    "    \n",
    "    # Se elimina la columna del df original\n",
    "    df = df.drop(columns=[nombre_columna])\n",
    "    return df, caracteristicas_generadas\n",
    "\n",
    "df_entrenamiento, caracteristicas_tiempo_generadas_train = dividirTimeStamp(df_entrenamiento, columna_timestamp)\n",
    "df_prueba, _ = dividirTimeStamp(df_prueba, columna_timestamp) # No necesitamos la lista de test, asumimos que es la misma\n",
    "\n",
    "todas_columnas_numericas = columnas_numericas_base + caracteristicas_tiempo_generadas_train\n",
    "\n",
    "print(f\"\\nNuevas características de tiempo generadas: {caracteristicas_tiempo_generadas_train}\")\n",
    "print(f\"Todas las características numéricas para imputación serán: {todas_columnas_numericas}\")\n",
    "print(df_entrenamiento.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29951c",
   "metadata": {},
   "source": [
    "## Quitar los Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e932b",
   "metadata": {},
   "source": [
    "### En las Numericas\n",
    "Hay dos opciones: \n",
    "\n",
    "Imputar con la Mediana, se entrena a un modelo y se sustituye los Nan con la prediccion. Es buena pero no siempre fiable\n",
    "\n",
    "Imputar con KNNImputer, una version mas avanzada de imputar con la mediana. El problema es que hay que escalar los datos antes de pasarlos por el Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f214c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento_procesado = df_entrenamiento.copy()\n",
    "df_prueba_procesado = df_prueba.copy()\n",
    "\n",
    "# Columnas numéricas existentes en los dataframes para imputar\n",
    "columnas_numericas_a_imputar_train = [col for col in todas_columnas_numericas if col in df_entrenamiento_procesado.columns]\n",
    "columnas_numericas_a_imputar_test = [col for col in todas_columnas_numericas if col in df_prueba_procesado.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0620253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimputador_mediana = SimpleImputer(strategy='median')\\ndf_entrenamiento_procesado[columnas_numericas_a_imputar_train] = imputador_mediana.fit_transform(df_entrenamiento_procesado[columnas_numericas_a_imputar_train])\\n\\ncols_comunes_test = [col for col in columnas_numericas_a_imputar_test if col in imputador_mediana.feature_names_in_]\\ndf_prueba_procesado[cols_comunes_test] = imputador_mediana.transform(df_prueba_procesado[cols_comunes_test])\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputacion de la mediana ==> Peor || Comentado para que no ejecute\n",
    "\"\"\"\n",
    "imputador_mediana = SimpleImputer(strategy='median')\n",
    "df_entrenamiento_procesado[columnas_numericas_a_imputar_train] = imputador_mediana.fit_transform(df_entrenamiento_procesado[columnas_numericas_a_imputar_train])\n",
    "\n",
    "cols_comunes_test = [col for col in columnas_numericas_a_imputar_test if col in imputador_mediana.feature_names_in_]\n",
    "df_prueba_procesado[cols_comunes_test] = imputador_mediana.transform(df_prueba_procesado[cols_comunes_test])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb9e0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNImputer ==> La que mejor va\n",
    "escalador_knn = StandardScaler() \n",
    "\n",
    "# Para poder usar KNNImputer, hace falta escalar los datos\n",
    "df_entrenamiento_escalado_num = escalador_knn.fit_transform(df_entrenamiento_procesado[columnas_numericas_a_imputar_train])\n",
    "\n",
    "imputador_knn = KNNImputer(n_neighbors=5) \n",
    "df_entrenamiento_imputado_escalado = imputador_knn.fit_transform(df_entrenamiento_escalado_num) # Fit y transform en train escalado\n",
    "\n",
    "# Desescalar train\n",
    "df_entrenamiento_procesado[columnas_numericas_a_imputar_train] = escalador_knn.inverse_transform(df_entrenamiento_imputado_escalado)\n",
    "\n",
    "# Transformar test\n",
    "cols_comunes_test_knn = [col for col in columnas_numericas_a_imputar_test if col in escalador_knn.feature_names_in_]\n",
    "df_prueba_escalado_num = escalador_knn.transform(df_prueba_procesado[cols_comunes_test_knn])\n",
    "df_prueba_imputado_escalado = imputador_knn.transform(df_prueba_escalado_num) # Solo transform en test escalado\n",
    "df_prueba_procesado[cols_comunes_test_knn] = escalador_knn.inverse_transform(df_prueba_imputado_escalado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc453a",
   "metadata": {},
   "source": [
    "### En las categóricas\n",
    "Aqui simplemente reemplazamos los Nan por un nuevo valor llamado \"Desconocido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "430a8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_categoricas_a_imputar_train = [col for col in columnas_categoricas if col in df_entrenamiento_procesado.columns]\n",
    "columnas_categoricas_a_imputar_test = [col for col in columnas_categoricas if col in df_prueba_procesado.columns]\n",
    "\n",
    "imputador_constante_cat = SimpleImputer(strategy='constant', fill_value='Faltante') # Traducido \"Missing\"\n",
    "\n",
    "# Ajustar y transformar train\n",
    "df_entrenamiento_procesado[columnas_categoricas_a_imputar_train] = imputador_constante_cat.fit_transform(df_entrenamiento_procesado[columnas_categoricas_a_imputar_train])\n",
    "\n",
    "# Transformar test\n",
    "cols_comunes_test_cat = [col for col in columnas_categoricas_a_imputar_test if col in imputador_constante_cat.feature_names_in_]\n",
    "df_prueba_procesado[cols_comunes_test_cat] = imputador_constante_cat.transform(df_prueba_procesado[cols_comunes_test_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d70d80d",
   "metadata": {},
   "source": [
    "### Comprobacion de los Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5edc1601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comprobación de NaNs después de toda la imputación:\n",
      "NaNs en df_entrenamiento_procesado (solo columnas con NaNs):\n",
      "Series([], dtype: int64)\n",
      "\n",
      "NaNs en df_prueba_procesado (solo columnas con NaNs):\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComprobación de NaNs después de toda la imputación:\")\n",
    "print(\"NaNs en df_entrenamiento_procesado (solo columnas con NaNs):\")\n",
    "print(df_entrenamiento_procesado.isnull().sum().loc[lambda x: x > 0])\n",
    "print(\"\\nNaNs en df_prueba_procesado (solo columnas con NaNs):\")\n",
    "print(df_prueba_procesado.isnull().sum().loc[lambda x: x > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8eaaa",
   "metadata": {},
   "source": [
    "## Tratar las categoricas para los modelos\n",
    "Vamos a probar dos, OneHot y Target Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d123bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_entrenamiento_final y df_prueba_final serán el resultado de esta celda\n",
    "df_entrenamiento_final = df_entrenamiento_procesado.copy()\n",
    "df_prueba_final = df_prueba_procesado.copy()\n",
    "\n",
    "# Columnas categóricas existentes para la codificación\n",
    "columnas_categoricas_a_codificar_train = [col for col in columnas_categoricas if col in df_entrenamiento_final.columns]\n",
    "columnas_categoricas_a_codificar_test = [col for col in columnas_categoricas if col in df_prueba_final.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b3d6d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncodificador_ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')\\n\\n# Ajustar y transformar train\\nmatriz_codificada_entrenamiento = codificador_ohe.fit_transform(df_entrenamiento_final[columnas_categoricas_a_codificar_train])\\ndf_codificado_entrenamiento = pd.DataFrame(matriz_codificada_entrenamiento, \\n                                            columns=codificador_ohe.get_feature_names_out(columnas_categoricas_a_codificar_train), \\n                                            index=df_entrenamiento_final.index)\\n\\n# Eliminar categóricas originales y unir las codificadas\\ndf_entrenamiento_final = df_entrenamiento_final.drop(columns=columnas_categoricas_a_codificar_train)\\ndf_entrenamiento_final = df_entrenamiento_final.join(df_codificado_entrenamiento)\\n\\n\\nmatriz_codificada_prueba = codificador_ohe.transform(df_prueba_final[columnas_categoricas_a_codificar_test])\\ndf_codificado_prueba = pd.DataFrame(matriz_codificada_prueba, \\n                                    columns=codificador_ohe.get_feature_names_out(columnas_categoricas_a_codificar_test), \\n                                    index=df_prueba_final.index)\\ndf_prueba_final = df_prueba_final.drop(columns=columnas_categoricas_a_codificar_test)\\ndf_prueba_final = df_prueba_final.join(df_codificado_prueba)\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHot ==> Peor || Comentado para que no ejecute\n",
    "\"\"\"\n",
    "codificador_ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')\n",
    "\n",
    "# Ajustar y transformar train\n",
    "matriz_codificada_entrenamiento = codificador_ohe.fit_transform(df_entrenamiento_final[columnas_categoricas_a_codificar_train])\n",
    "df_codificado_entrenamiento = pd.DataFrame(matriz_codificada_entrenamiento, \n",
    "                                            columns=codificador_ohe.get_feature_names_out(columnas_categoricas_a_codificar_train), \n",
    "                                            index=df_entrenamiento_final.index)\n",
    "\n",
    "# Eliminar categóricas originales y unir las codificadas\n",
    "df_entrenamiento_final = df_entrenamiento_final.drop(columns=columnas_categoricas_a_codificar_train)\n",
    "df_entrenamiento_final = df_entrenamiento_final.join(df_codificado_entrenamiento)\n",
    "\n",
    "\n",
    "matriz_codificada_prueba = codificador_ohe.transform(df_prueba_final[columnas_categoricas_a_codificar_test])\n",
    "df_codificado_prueba = pd.DataFrame(matriz_codificada_prueba, \n",
    "                                    columns=codificador_ohe.get_feature_names_out(columnas_categoricas_a_codificar_test), \n",
    "                                    index=df_prueba_final.index)\n",
    "df_prueba_final = df_prueba_final.drop(columns=columnas_categoricas_a_codificar_test)\n",
    "df_prueba_final = df_prueba_final.join(df_codificado_prueba)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3770e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target encoder ==> Mejor\n",
    "codificador_objetivo = ce.TargetEncoder(cols=columnas_categoricas_a_codificar_train, smoothing=10.0)\n",
    "\n",
    "# Ajustar y transformar train (modifica el DataFrame directamente)\n",
    "df_entrenamiento_final[columnas_categoricas_a_codificar_train] = codificador_objetivo.fit_transform(df_entrenamiento_final[columnas_categoricas_a_codificar_train], df_entrenamiento_final[objetivo])\n",
    "\n",
    "# Transformar test\n",
    "df_prueba_final[columnas_categoricas_a_codificar_test] = codificador_objetivo.transform(df_prueba_final[columnas_categoricas_a_codificar_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8225c8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma de df_entrenamiento_final (después de codificación categórica): (15000, 12)\n",
      "Tipos de datos en df_entrenamiento_final:\n",
      "modo_operacion      float64\n",
      "operador            float64\n",
      "temperatura         float64\n",
      "presion             float64\n",
      "sensor_ruido        float64\n",
      "sensor_3            float64\n",
      "fallo                 int64\n",
      "hora                float64\n",
      "dia_semana          float64\n",
      "mes                 float64\n",
      "dia_del_anio        float64\n",
      "es_fin_de_semana    float64\n",
      "dtype: object\n",
      "\n",
      "Verificación final de NaNs en df_entrenamiento_final (deberían ser 0):\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nForma de df_entrenamiento_final (después de codificación categórica): {df_entrenamiento_final.shape if 'df_entrenamiento_final' in locals() else 'No definido'}\")\n",
    "if 'df_entrenamiento_final' in locals() and not df_entrenamiento_final.empty:\n",
    "    print(\"Tipos de datos en df_entrenamiento_final:\")\n",
    "    print(df_entrenamiento_final.dtypes)\n",
    "    print(\"\\nVerificación final de NaNs en df_entrenamiento_final (deberían ser 0):\")\n",
    "    print(df_entrenamiento_final.isnull().sum().loc[lambda x: x > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d42bbaa",
   "metadata": {},
   "source": [
    "## Datos sin Tocar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88a50e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento_base = df_entrenamiento_final.copy()\n",
    "df_prueba_base = df_prueba_final.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70344827",
   "metadata": {},
   "source": [
    "## Datos quitando las no prometedoras (Sensor Ruido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebccf481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento_reducido = df_entrenamiento_final.copy()\n",
    "df_prueba_reducido = df_prueba_final.copy()\n",
    "columna_a_quitar = 'sensor_ruido' # Es la unica que no aumenta la informacion, o la que parece al menos que no\n",
    "\n",
    "df_entrenamiento_reducido = df_entrenamiento_reducido.drop(columns=[columna_a_quitar])\n",
    "df_prueba_reducido = df_prueba_reducido.drop(columns=[columna_a_quitar])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d914e",
   "metadata": {},
   "source": [
    "## Datos relacionados TODOS con TODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32d02f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento_interacciones = df_entrenamiento_final.copy()\n",
    "df_prueba_interacciones = df_prueba_final.copy()\n",
    "\n",
    "\n",
    "for col1, col2 in itertools.combinations(columnas_numericas_base, 2): # Mejor un paquete para las iteraciones :)\n",
    "\n",
    "    nombre_col_interaccion = f\"{col1}_x_{col2}\" \n",
    "    df_entrenamiento_interacciones[nombre_col_interaccion] = df_entrenamiento_interacciones[col1] * df_entrenamiento_interacciones[col2]\n",
    "    \n",
    "    df_prueba_interacciones[nombre_col_interaccion] = df_prueba_interacciones[col1] * df_prueba_interacciones[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2265d7a",
   "metadata": {},
   "source": [
    "# Probar modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe00ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dc178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Evaluación de Modelos ---\n",
      "\n",
      "======================================================================\n",
      "--- Evaluando Conjunto de Datos: Base (Forma: (15000, 12)) ---\n",
      "======================================================================\n",
      "\n",
      "  --- Modelo: Proceso Gaussiano ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10d2cc540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10d0f8540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10b3b8540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10cdb4540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  --- Modelo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_modelo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     puntuaciones_cv_f1 = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstancia_modelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_entrenamiento\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_entrenamiento\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkfold_estratificado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluador_f1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m     55\u001b[39m     f1_promedio_modelo = np.mean(puntuaciones_cv_f1) \n\u001b[32m     56\u001b[39m     desv_est_f1_modelo = np.std(puntuaciones_cv_f1) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/__PITON/UNI312/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Bucle de Entrenamiento y Evaluación de Modelos ---\n",
    "print(\"\\n--- Iniciando Evaluación de Modelos ---\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "conjuntos_datos_a_evaluar = []\n",
    "\n",
    "conjuntos_datos_a_evaluar.append({'nombre': 'Base', 'datos': df_entrenamiento_base})\n",
    "conjuntos_datos_a_evaluar.append({'nombre': 'Caracteristicas Reducidas', 'datos': df_entrenamiento_reducido})\n",
    "conjuntos_datos_a_evaluar.append({'nombre': 'Interaccion de Caracteristicas', 'datos': df_entrenamiento_interacciones})\n",
    "\n",
    "\n",
    "# Preparar lista de modelos\n",
    "modelos_a_evaluar = [\n",
    "    #('Árbol de Decisión', DecisionTreeClassifier(random_state=42, max_depth=500)), # Traducido\n",
    "    #('Naive Bayes Gaussiano', GaussianNB()), # Traducido\n",
    "    #('Random Forest', RandomForestClassifier(random_state=42, n_jobs=-1)),\n",
    "    #('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "    #('Bagging', BaggingClassifier(random_state=42, n_jobs=-1)),\n",
    "    ('XGBoost', xgb.XGBClassifier(random_state=42, eval_metric='mlogloss', n_jobs=-1, max_depth = 1000, device = 'gpu'))\n",
    "]\n",
    "\n",
    "# Definir StratifiedKFold y el F1 scorer\n",
    "evaluador_f1 = make_scorer(f1_score, pos_label=1, zero_division=0)\n",
    "num_divisiones = 4 \n",
    "kfold_estratificado = StratifiedKFold(n_splits=num_divisiones, shuffle=True, random_state=42) \n",
    "\n",
    "resultados_completos = {} \n",
    "resumen_f1_promedio = {} \n",
    "\n",
    "for info_conjunto in conjuntos_datos_a_evaluar: \n",
    "    nombre_conjunto = info_conjunto['nombre'] \n",
    "    df_actual_entrenamiento = info_conjunto['datos'] \n",
    "    \n",
    "    print(f\"\\n======================================================================\")\n",
    "    print(f\"--- Evaluando Conjunto de Datos: {nombre_conjunto} (Forma: {df_actual_entrenamiento.shape}) ---\")\n",
    "    print(f\"======================================================================\")\n",
    "\n",
    "    if objetivo not in df_actual_entrenamiento.columns:\n",
    "        print(f\"  ERROR: La columna objetivo '{objetivo}' no se encuentra en '{nombre_conjunto}'. Omitiendo.\")\n",
    "        continue\n",
    "\n",
    "    X_entrenamiento = df_actual_entrenamiento.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_actual_entrenamiento[objetivo] \n",
    "    \n",
    "    \n",
    "    resumen_f1_promedio[nombre_conjunto] = {}\n",
    "    resultados_completos[nombre_conjunto] = {}\n",
    "\n",
    "    for nombre_modelo, instancia_modelo in modelos_a_evaluar: \n",
    "        print(f\"\\n  --- Modelo: {nombre_modelo} ---\")\n",
    "        try:\n",
    "            puntuaciones_cv_f1 = cross_val_score(instancia_modelo, X_entrenamiento, y_entrenamiento, cv=kfold_estratificado, scoring=evaluador_f1, n_jobs=-1) \n",
    "            \n",
    "            f1_promedio_modelo = np.mean(puntuaciones_cv_f1) \n",
    "            desv_est_f1_modelo = np.std(puntuaciones_cv_f1) \n",
    "            \n",
    "            resumen_f1_promedio[nombre_conjunto][nombre_modelo] = f1_promedio_modelo\n",
    "            resultados_completos[nombre_conjunto][nombre_modelo] = {'f1_promedio': f1_promedio_modelo, 'desv_est_f1': desv_est_f1_modelo, 'f1_por_fold': puntuaciones_cv_f1.tolist()}\n",
    "            \n",
    "            print(f\"    F1-Score Promedio ({num_divisiones} folds): {f1_promedio_modelo:.4f} (std: {desv_est_f1_modelo:.4f})\")\n",
    "            print(f\"    F1-Scores por fold: {[round(s, 4) for s in puntuaciones_cv_f1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR al entrenar/evaluar {nombre_modelo} en {nombre_conjunto}: {e}\")\n",
    "            resumen_f1_promedio[nombre_conjunto][nombre_modelo] = np.nan\n",
    "            resultados_completos[nombre_conjunto][nombre_modelo] = {'f1_promedio': np.nan, 'desv_est_f1': np.nan, 'f1_por_fold': [], 'error': str(e)}\n",
    "\n",
    "# Imprimir tabla resumen\n",
    "print(f\"\\n\\n======================================================================\")\n",
    "print(f\"--- Tabla Resumen de F1-Score Promedio (clase positiva=1) ---\")\n",
    "print(f\"======================================================================\")\n",
    "\n",
    "\n",
    "df_resumen = pd.DataFrame(resumen_f1_promedio).T \n",
    "orden_modelos = [name for name, _ in modelos_a_evaluar] \n",
    "columnas_existentes_modelos = [m for m in orden_modelos if m in df_resumen.columns] \n",
    "if columnas_existentes_modelos:\n",
    "    df_resumen = df_resumen[columnas_existentes_modelos]\n",
    "\n",
    "print(df_resumen.to_string(float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69617b42",
   "metadata": {},
   "source": [
    "## Funcion Predict Modelo\n",
    "Esta funcion, dado un modelo y una df hace un predict y lo guarda en su correspondiente csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96b472c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCSV(model, model_name, df_toPredict, df_name):\n",
    "    columns = ['id', 'fallo']\n",
    "    csv_file = f\"CSVModelos/{model_name}_{df_name}.csv\"\n",
    "    header = True\n",
    "\n",
    "    for i in range(0, len(df_toPredict), 500):\n",
    "        test_predict = model.predict(df_toPredict[i:i+500])\n",
    "        \n",
    "        indi = [j for j in range(i, i+500,1)]\n",
    "        valor = [test_predict[k] for k in range(500)]\n",
    "\n",
    "        results = pd.DataFrame(list(zip(indi,valor)), columns=columns)\n",
    "\n",
    "        results.to_csv(csv_file, mode='a', header=header, index=False)\n",
    "        header = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e41fa",
   "metadata": {},
   "source": [
    "## DECISIONTREE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7559a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictArbolDecision():\n",
    "    df_to_train = df_entrenamiento_reducido.copy()\n",
    "    df_toTest = df_prueba_reducido.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"ArbolDecision\",df_toTest,\"Reducido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81a0cd",
   "metadata": {},
   "source": [
    "## NAIVEBAYES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "afac54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNaiveBayes():\n",
    "    df_to_train = df_entrenamiento_base.copy()\n",
    "    df_toTest = df_prueba_base.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"NaiveBayes\",df_toTest,\"Basico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263a810",
   "metadata": {},
   "source": [
    "## RANDOMFOREST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b64c26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRandomForest():\n",
    "    df_to_train = df_entrenamiento_reducido.copy()\n",
    "    df_toTest = df_prueba_reducido.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"RandomForest\",df_toTest,\"Reducido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fde86",
   "metadata": {},
   "source": [
    "## GRADIENTBOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8290927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictGradientBoosting():\n",
    "    df_to_train = df_entrenamiento_base.copy()\n",
    "    df_toTest = df_prueba_base.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"GradientBoosting\",df_toTest,\"Basico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08206b80",
   "metadata": {},
   "source": [
    "## BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cf294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictBagging():\n",
    "    df_to_train = df_entrenamiento_reducido.copy()\n",
    "    df_toTest = df_prueba_reducido.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = BaggingClassifier(random_state=42, n_jobs=-1)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"ArbolDecision\",df_toTest,\"Reducido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255b878",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8670de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictXGBoost():\n",
    "    df_to_train = df_entrenamiento_reducido.copy()\n",
    "    df_toTest = df_prueba_reducido.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss', n_jobs=-1, max_depth = 500, device = 'gpu')\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"XGBoost\",df_toTest,\"Reducido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b31061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10d2d8540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10b880540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10d670540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10d514540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10bc7c540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10bc14540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10b584540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10f3f8540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "#predictArbolDecision()\n",
    "#predictNaiveBayes()\n",
    "#predictRandomForest()\n",
    "#predictGradientBoosting()\n",
    "#predictBagging()\n",
    "#predictXGBoost()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNI312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
