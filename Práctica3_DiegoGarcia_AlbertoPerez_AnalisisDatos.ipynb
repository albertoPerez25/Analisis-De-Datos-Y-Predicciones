{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88692b0b",
   "metadata": {},
   "source": [
    "# Importamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b92cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos train.csv y test.csv...\n",
      "Datos cargados correctamente.\n",
      "\n",
      "Primeras 5 filas de df_entrenamiento_bruto:\n",
      "      id            timestamp modo_operacion operador  temperatura    presion  \\\n",
      "0  15000  2021-04-24 03:00:00  mantenimiento      NaN    20.428941  58.474497   \n",
      "1  15001  2020-09-26 19:00:00  mantenimiento        E     1.332931  84.784184   \n",
      "2  15002  2021-07-02 15:00:00           auto        D    17.501579  65.057682   \n",
      "3  15003  2020-02-05 22:00:00           auto      NaN     8.118801  70.127615   \n",
      "4  15004  2020-09-05 18:00:00         manual      NaN    -0.353122  90.738090   \n",
      "\n",
      "   sensor_ruido   sensor_3  fallo  \n",
      "0      0.349400  18.301299      0  \n",
      "1     -2.252684   7.295245      0  \n",
      "2      0.359853  34.271305      0  \n",
      "3      0.489166  -3.748938      0  \n",
      "4     -1.505866  10.157637      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import category_encoders as ce # Para Target Encoding si se usa\n",
    "import itertools # Para generar combinaciones de características\n",
    "import warnings\n",
    "\n",
    "# Ignorar warnings para mantener la salida limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar datos\n",
    "print(\"Cargando datos train.csv y test.csv...\")\n",
    "try:\n",
    "    df_entrenamiento_bruto = pd.read_csv('train.csv')\n",
    "    df_prueba_bruto = pd.read_csv('test.csv')\n",
    "    print(\"Datos cargados correctamente.\")\n",
    "    print(\"\\nPrimeras 5 filas de df_entrenamiento_bruto:\")\n",
    "    print(df_entrenamiento_bruto.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Asegúrate de que 'train.csv' y 'test.csv' estén en el directorio correcto.\")\n",
    "    df_entrenamiento_bruto = pd.DataFrame() \n",
    "    df_prueba_bruto = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89dc438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Variables Globales Definidas ---\n",
      "  Objetivo: fallo\n",
      "  Características numéricas base: ['temperatura', 'presion', 'sensor_ruido', 'sensor_3']\n",
      "  Características categóricas: ['modo_operacion', 'operador']\n",
      "  Columna ID a eliminar: id\n",
      "  Columna Timestamp a procesar: timestamp\n",
      "\n",
      "NaNs en df_entrenamiento_bruto:\n",
      "id                   0\n",
      "timestamp            0\n",
      "modo_operacion       0\n",
      "operador          2731\n",
      "temperatura          0\n",
      "presion            625\n",
      "sensor_ruido         0\n",
      "sensor_3             0\n",
      "fallo                0\n",
      "dtype: int64\n",
      "\n",
      "NaNs en df_prueba_bruto:\n",
      "id                   0\n",
      "timestamp            0\n",
      "modo_operacion       0\n",
      "operador          2700\n",
      "temperatura          0\n",
      "presion            625\n",
      "sensor_ruido         0\n",
      "sensor_3             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Variables Globales y Listas de Características ---\n",
    "objetivo = 'fallo'\n",
    "\n",
    "# Características originales\n",
    "columnas_numericas_base = ['temperatura', 'presion', 'sensor_ruido', 'sensor_3']\n",
    "columnas_categoricas = ['modo_operacion', 'operador'] # Renombrado desde _base para claridad\n",
    "\n",
    "# Columnas a procesar especialmente\n",
    "columna_id = 'id'\n",
    "columna_timestamp = 'timestamp'\n",
    "\n",
    "print(\"--- Variables Globales Definidas ---\")\n",
    "print(f\"  Objetivo: {objetivo}\")\n",
    "print(f\"  Características numéricas base: {columnas_numericas_base}\")\n",
    "print(f\"  Características categóricas: {columnas_categoricas}\")\n",
    "print(f\"  Columna ID a eliminar: {columna_id}\")\n",
    "print(f\"  Columna Timestamp a procesar: {columna_timestamp}\")\n",
    "\n",
    "# Mostrar NaNs iniciales\n",
    "if not df_entrenamiento_bruto.empty:\n",
    "    print(\"\\nNaNs en df_entrenamiento_bruto:\")\n",
    "    print(df_entrenamiento_bruto.isnull().sum())\n",
    "if not df_prueba_bruto.empty:\n",
    "    print(\"\\nNaNs en df_prueba_bruto:\")\n",
    "    print(df_prueba_bruto.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec400d",
   "metadata": {},
   "source": [
    "# Preparamos Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53db7b",
   "metadata": {},
   "source": [
    "## Columnas id y TimeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a65e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Preprocesamiento ---\n",
      "\n",
      "Procesando columna ID: 'id'...\n",
      "  Eliminando 'id' de df_entrenamiento.\n",
      "  Eliminando 'id' de df_prueba.\n",
      "\n",
      "Realizando ingeniería de características para la columna: 'timestamp'...\n",
      "  Convirtiendo 'timestamp' a datetime...\n",
      "  Extrayendo características de tiempo de 'timestamp'...\n",
      "  Eliminando la columna original 'timestamp'.\n",
      "  Convirtiendo 'timestamp' a datetime...\n",
      "  Extrayendo características de tiempo de 'timestamp'...\n",
      "  Eliminando la columna original 'timestamp'.\n",
      "\n",
      "Nuevas características de tiempo generadas: ['hora', 'dia_semana', 'mes', 'dia_del_anio', 'es_fin_de_semana']\n",
      "Todas las características numéricas para imputación serán: ['temperatura', 'presion', 'sensor_ruido', 'sensor_3', 'hora', 'dia_semana', 'mes', 'dia_del_anio', 'es_fin_de_semana']\n",
      "\n",
      "Primeras 5 filas de df_entrenamiento después de procesar ID y timestamp:\n",
      "  modo_operacion operador  temperatura    presion  sensor_ruido   sensor_3  \\\n",
      "0  mantenimiento      NaN    20.428941  58.474497      0.349400  18.301299   \n",
      "1  mantenimiento        E     1.332931  84.784184     -2.252684   7.295245   \n",
      "2           auto        D    17.501579  65.057682      0.359853  34.271305   \n",
      "3           auto      NaN     8.118801  70.127615      0.489166  -3.748938   \n",
      "4         manual      NaN    -0.353122  90.738090     -1.505866  10.157637   \n",
      "\n",
      "   fallo  hora  dia_semana  mes  dia_del_anio  es_fin_de_semana  \n",
      "0      0     3           5    4           114                 1  \n",
      "1      0    19           5    9           270                 1  \n",
      "2      0    15           4    7           183                 0  \n",
      "3      0    22           2    2            36                 0  \n",
      "4      0    18           5    9           249                 1  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Iniciando Preprocesamiento ---\")\n",
    "if not df_entrenamiento_bruto.empty:\n",
    "    # Crear copias de trabajo\n",
    "    df_entrenamiento = df_entrenamiento_bruto.copy()\n",
    "    df_prueba = df_prueba_bruto.copy()\n",
    "\n",
    "    # --- 3.1. Manejar columna 'id' ---\n",
    "    print(f\"\\nProcesando columna ID: '{columna_id}'...\")\n",
    "    if columna_id in df_entrenamiento.columns:\n",
    "        print(f\"  Eliminando '{columna_id}' de df_entrenamiento.\")\n",
    "        df_entrenamiento = df_entrenamiento.drop(columns=[columna_id])\n",
    "    if columna_id in df_prueba.columns:\n",
    "        print(f\"  Eliminando '{columna_id}' de df_prueba.\")\n",
    "        df_prueba = df_prueba.drop(columns=[columna_id])\n",
    "\n",
    "    # --- 3.2. Ingeniería de Características para 'timestamp' ---\n",
    "    print(f\"\\nRealizando ingeniería de características para la columna: '{columna_timestamp}'...\")\n",
    "    def ingenieria_caracteristicas_tiempo(df, nombre_columna):\n",
    "        if nombre_columna not in df.columns:\n",
    "            print(f\"  Advertencia: La columna '{nombre_columna}' no existe en el DataFrame. Omitiendo ingeniería de tiempo.\")\n",
    "            return df, []\n",
    "            \n",
    "        print(f\"  Convirtiendo '{nombre_columna}' a datetime...\")\n",
    "        df[nombre_columna] = pd.to_datetime(df[nombre_columna])\n",
    "        print(f\"  Extrayendo características de tiempo de '{nombre_columna}'...\")\n",
    "        df['hora'] = df[nombre_columna].dt.hour\n",
    "        df['dia_semana'] = df[nombre_columna].dt.dayofweek # Lunes=0, Domingo=6\n",
    "        df['mes'] = df[nombre_columna].dt.month\n",
    "        df['dia_del_anio'] = df[nombre_columna].dt.dayofyear # Renombrado para claridad\n",
    "        df['es_fin_de_semana'] = (df[nombre_columna].dt.dayofweek >= 5).astype(int) # Renombrado\n",
    "        \n",
    "        caracteristicas_generadas = ['hora', 'dia_semana', 'mes', 'dia_del_anio', 'es_fin_de_semana']\n",
    "        \n",
    "        print(f\"  Eliminando la columna original '{nombre_columna}'.\")\n",
    "        df = df.drop(columns=[nombre_columna])\n",
    "        return df, caracteristicas_generadas\n",
    "\n",
    "    df_entrenamiento, caracteristicas_tiempo_generadas_train = ingenieria_caracteristicas_tiempo(df_entrenamiento, columna_timestamp)\n",
    "    df_prueba, _ = ingenieria_caracteristicas_tiempo(df_prueba, columna_timestamp) # No necesitamos la lista de test, asumimos que es la misma\n",
    "\n",
    "    # Lista completa de características numéricas (incluyendo las de tiempo)\n",
    "    # Asegurar que solo se añaden si se generaron (por si timestamp_column faltara)\n",
    "    todas_columnas_numericas = columnas_numericas_base + caracteristicas_tiempo_generadas_train\n",
    "\n",
    "    print(f\"\\nNuevas características de tiempo generadas: {caracteristicas_tiempo_generadas_train}\")\n",
    "    print(f\"Todas las características numéricas para imputación serán: {todas_columnas_numericas}\")\n",
    "    print(\"\\nPrimeras 5 filas de df_entrenamiento después de procesar ID y timestamp:\")\n",
    "    print(df_entrenamiento.head())\n",
    "else:\n",
    "    print(\"Error: df_entrenamiento_bruto no está definido o está vacío. Ejecuta las celdas anteriores.\")\n",
    "    # Crear DataFrames vacíos para evitar errores en celdas subsiguientes si se desea continuar\n",
    "    df_entrenamiento = pd.DataFrame()\n",
    "    df_prueba = pd.DataFrame()\n",
    "    todas_columnas_numericas = columnas_numericas_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29951c",
   "metadata": {},
   "source": [
    "## Quitar los Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e932b",
   "metadata": {},
   "source": [
    "### En las Numericas\n",
    "Hay dos opciones: \n",
    "\n",
    "Imputar con la Mediana, se entrena a un modelo y se sustituye los Nan con la prediccion. Es buena pero no siempre fiable\n",
    "\n",
    "Imputar con KNNImputer, una version mas avanzada de imputar con la mediana. El problema es que hay que escalar los datos antes de pasarlos por el Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0620253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Usando Imputación por Mediana...\n"
     ]
    }
   ],
   "source": [
    "df_entrenamiento_procesado = df_entrenamiento.copy()\n",
    "df_prueba_procesado = df_prueba.copy()\n",
    "\n",
    "# Columnas numéricas existentes en los dataframes para imputar\n",
    "columnas_numericas_a_imputar_train = [col for col in todas_columnas_numericas if col in df_entrenamiento_procesado.columns]\n",
    "columnas_numericas_a_imputar_test = [col for col in todas_columnas_numericas if col in df_prueba_procesado.columns]\n",
    "\n",
    "print(\"  Usando Imputación por Mediana...\")\n",
    "if columnas_numericas_a_imputar_train:\n",
    "    imputador_mediana = SimpleImputer(strategy='median')\n",
    "    df_entrenamiento_procesado[columnas_numericas_a_imputar_train] = imputador_mediana.fit_transform(df_entrenamiento_procesado[columnas_numericas_a_imputar_train])\n",
    "    if columnas_numericas_a_imputar_test:\n",
    "        # Asegurar que test tenga las mismas columnas numéricas que se ajustaron en train\n",
    "        cols_comunes_test = [col for col in columnas_numericas_a_imputar_test if col in imputador_mediana.feature_names_in_]\n",
    "        if cols_comunes_test:\n",
    "            df_prueba_procesado[cols_comunes_test] = imputador_mediana.transform(df_prueba_procesado[cols_comunes_test])\n",
    "else:\n",
    "    print(\"  No hay columnas numéricas para imputar con Mediana en el set de entrenamiento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9e0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "escalador_knn = StandardScaler() \n",
    "\n",
    "# Ajustar y transformar train\n",
    "df_entrenamiento_escalado_num = escalador_knn.fit_transform(df_entrenamiento_procesado[columnas_numericas_a_imputar_train])\n",
    "\n",
    "imputador_knn = KNNImputer(n_neighbors=5) \n",
    "df_entrenamiento_imputado_escalado = imputador_knn.fit_transform(df_entrenamiento_escalado_num) # Fit y transform en train escalado\n",
    "\n",
    "# Desescalar train\n",
    "df_entrenamiento_procesado[columnas_numericas_a_imputar_train] = escalador_knn.inverse_transform(df_entrenamiento_imputado_escalado)\n",
    "\n",
    "# Transformar test\n",
    "if columnas_numericas_a_imputar_test:\n",
    "    # Asegurar que test tenga las mismas columnas numéricas que se ajustaron/escalaron en train\n",
    "    cols_comunes_test_knn = [col for col in columnas_numericas_a_imputar_test if col in escalador_knn.feature_names_in_]\n",
    "    if cols_comunes_test_knn:\n",
    "        df_prueba_escalado_num = escalador_knn.transform(df_prueba_procesado[cols_comunes_test_knn])\n",
    "        df_prueba_imputado_escalado = imputador_knn.transform(df_prueba_escalado_num) # Solo transform en test escalado\n",
    "        df_prueba_procesado[cols_comunes_test_knn] = escalador_knn.inverse_transform(df_prueba_imputado_escalado)\n",
    "    else:\n",
    "        print(\"    Advertencia: No hay columnas numéricas coincidentes en el test set para KNNImputer después del escalado de train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc453a",
   "metadata": {},
   "source": [
    "### En las categóricas\n",
    "Aqui simplemente reemplazamos los Nan por un nuevo valor llamado \"Desconocido\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430a8414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Imputando NaNs en columnas categóricas con 'Faltante'.\n",
      "\n",
      "Comprobación de NaNs después de toda la imputación:\n",
      "NaNs en df_entrenamiento_procesado (solo columnas con NaNs):\n",
      "Series([], dtype: int64)\n",
      "\n",
      "NaNs en df_prueba_procesado (solo columnas con NaNs):\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "columnas_categoricas_a_imputar_train = [col for col in columnas_categoricas if col in df_entrenamiento_procesado.columns]\n",
    "columnas_categoricas_a_imputar_test = [col for col in columnas_categoricas if col in df_prueba_procesado.columns]\n",
    "\n",
    "imputador_constante_cat = SimpleImputer(strategy='constant', fill_value='Faltante') # Traducido \"Missing\"\n",
    "\n",
    "# Ajustar y transformar train\n",
    "df_entrenamiento_procesado[columnas_categoricas_a_imputar_train] = imputador_constante_cat.fit_transform(df_entrenamiento_procesado[columnas_categoricas_a_imputar_train])\n",
    "\n",
    "# Transformar test\n",
    "if columnas_categoricas_a_imputar_test:\n",
    "    # Asegurar que test tenga las mismas columnas categóricas que se ajustaron en train\n",
    "    cols_comunes_test_cat = [col for col in columnas_categoricas_a_imputar_test if col in imputador_constante_cat.feature_names_in_]\n",
    "    if cols_comunes_test_cat:\n",
    "            df_prueba_procesado[cols_comunes_test_cat] = imputador_constante_cat.transform(df_prueba_procesado[cols_comunes_test_cat])\n",
    "print(f\"  Imputando NaNs en columnas categóricas con '{imputador_constante_cat.fill_value}'.\")\n",
    "\n",
    "\n",
    "print(\"\\nComprobación de NaNs después de toda la imputación:\")\n",
    "print(\"NaNs en df_entrenamiento_procesado (solo columnas con NaNs):\")\n",
    "print(df_entrenamiento_procesado.isnull().sum().loc[lambda x: x > 0])\n",
    "print(\"\\nNaNs en df_prueba_procesado (solo columnas con NaNs):\")\n",
    "print(df_prueba_procesado.isnull().sum().loc[lambda x: x > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8eaaa",
   "metadata": {},
   "source": [
    "## Tratar las categoricas para los modelos\n",
    "Vamos a probar dos, OneHot y Target Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d123bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_entrenamiento_final y df_prueba_final serán el resultado de esta celda\n",
    "df_entrenamiento_final = df_entrenamiento_procesado.copy()\n",
    "df_prueba_final = df_prueba_procesado.copy()\n",
    "\n",
    "# Columnas categóricas existentes para la codificación\n",
    "columnas_categoricas_a_codificar_train = [col for col in columnas_categoricas if col in df_entrenamiento_final.columns]\n",
    "columnas_categoricas_a_codificar_test = [col for col in columnas_categoricas if col in df_prueba_final.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3d6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "codificador_ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')\n",
    "\n",
    "# Ajustar y transformar train\n",
    "matriz_codificada_entrenamiento = codificador_ohe.fit_transform(df_entrenamiento_final[columnas_categoricas_a_codificar_train])\n",
    "df_codificado_entrenamiento = pd.DataFrame(matriz_codificada_entrenamiento, \n",
    "                                            columns=codificador_ohe.get_feature_names_out(columnas_categoricas_a_codificar_train), \n",
    "                                            index=df_entrenamiento_final.index)\n",
    "\n",
    "# Eliminar categóricas originales y unir las codificadas\n",
    "df_entrenamiento_final = df_entrenamiento_final.drop(columns=columnas_categoricas_a_codificar_train)\n",
    "df_entrenamiento_final = df_entrenamiento_final.join(df_codificado_entrenamiento)\n",
    "\n",
    "\n",
    "matriz_codificada_prueba = codificador_ohe.transform(df_prueba_final[columnas_categoricas_a_codificar_test])\n",
    "df_codificado_prueba = pd.DataFrame(matriz_codificada_prueba, \n",
    "                                    columns=codificador_ohe.get_feature_names_out(columnas_categoricas_a_codificar_test), \n",
    "                                    index=df_prueba_final.index)\n",
    "df_prueba_final = df_prueba_final.drop(columns=columnas_categoricas_a_codificar_test)\n",
    "df_prueba_final = df_prueba_final.join(df_codificado_prueba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3770e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "codificador_objetivo = ce.TargetEncoder(cols=columnas_categoricas_a_codificar_train, smoothing=10.0)\n",
    "\n",
    "# Ajustar y transformar train (modifica el DataFrame directamente)\n",
    "df_entrenamiento_final[columnas_categoricas_a_codificar_train] = codificador_objetivo.fit_transform(df_entrenamiento_final[columnas_categoricas_a_codificar_train], df_entrenamiento_final[objetivo])\n",
    "\n",
    "# Transformar test\n",
    "df_prueba_final[columnas_categoricas_a_codificar_test] = codificador_objetivo.transform(df_prueba_final[columnas_categoricas_a_codificar_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8225c8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma de df_entrenamiento_final (después de codificación categórica): (15000, 17)\n",
      "Tipos de datos en df_entrenamiento_final:\n",
      "temperatura                     float64\n",
      "presion                         float64\n",
      "sensor_ruido                    float64\n",
      "sensor_3                        float64\n",
      "fallo                             int64\n",
      "hora                            float64\n",
      "dia_semana                      float64\n",
      "mes                             float64\n",
      "dia_del_anio                    float64\n",
      "es_fin_de_semana                float64\n",
      "modo_operacion_mantenimiento    float64\n",
      "modo_operacion_manual           float64\n",
      "operador_C                      float64\n",
      "operador_D                      float64\n",
      "operador_E                      float64\n",
      "operador_F                      float64\n",
      "operador_Faltante               float64\n",
      "dtype: object\n",
      "\n",
      "Verificación final de NaNs en df_entrenamiento_final (deberían ser 0):\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nForma de df_entrenamiento_final (después de codificación categórica): {df_entrenamiento_final.shape if 'df_entrenamiento_final' in locals() else 'No definido'}\")\n",
    "if 'df_entrenamiento_final' in locals() and not df_entrenamiento_final.empty:\n",
    "    print(\"Tipos de datos en df_entrenamiento_final:\")\n",
    "    print(df_entrenamiento_final.dtypes)\n",
    "    print(\"\\nVerificación final de NaNs en df_entrenamiento_final (deberían ser 0):\")\n",
    "    print(df_entrenamiento_final.isnull().sum().loc[lambda x: x > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d42bbaa",
   "metadata": {},
   "source": [
    "## Datos sin Tocar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a50e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento_base = df_entrenamiento_final.copy()\n",
    "df_prueba_base = df_prueba_final.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70344827",
   "metadata": {},
   "source": [
    "## Datos quitando las no prometedoras (Sensor Ruido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebccf481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento_reducido = df_entrenamiento_final.copy()\n",
    "df_prueba_reducido = df_prueba_final.copy()\n",
    "columna_a_quitar = 'sensor_ruido'\n",
    "\n",
    "if columna_a_quitar in df_entrenamiento_reducido.columns:\n",
    "    df_entrenamiento_reducido = df_entrenamiento_reducido.drop(columns=[columna_a_quitar])\n",
    "else:\n",
    "    print(f\"  Advertencia (Reducido - Train): Columna '{columna_a_quitar}' no encontrada para eliminar.\")\n",
    "if columna_a_quitar in df_prueba_reducido.columns:\n",
    "    df_prueba_reducido = df_prueba_reducido.drop(columns=[columna_a_quitar])\n",
    "else:\n",
    "    print(f\"  Advertencia (Reducido - Test): Columna '{columna_a_quitar}' no encontrada para eliminar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d914e",
   "metadata": {},
   "source": [
    "## Datos relacionados TODOS con TODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d02f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entrenamiento_interacciones = df_entrenamiento_final.copy()\n",
    "df_prueba_interacciones = df_prueba_final.copy()\n",
    "\n",
    "\n",
    "for col1, col2 in itertools.combinations(columnas_numericas_base, 2):\n",
    "    if col1 in df_entrenamiento_interacciones.columns and col2 in df_entrenamiento_interacciones.columns:\n",
    "        nombre_col_interaccion = f\"{col1}_x_{col2}\" # Renombrado\n",
    "        df_entrenamiento_interacciones[nombre_col_interaccion] = df_entrenamiento_interacciones[col1] * df_entrenamiento_interacciones[col2]\n",
    "        \n",
    "        if col1 in df_prueba_interacciones.columns and col2 in df_prueba_interacciones.columns:\n",
    "                df_prueba_interacciones[nombre_col_interaccion] = df_prueba_interacciones[col1] * df_prueba_interacciones[col2]\n",
    "        else:\n",
    "                print(f\"    Advertencia (Interacciones - Test): '{col1}' o '{col2}' no encontradas para crear '{nombre_col_interaccion}'. Se rellenará con 0.\")\n",
    "                df_prueba_interacciones[nombre_col_interaccion] = 0 # Imputar con 0 si falta en test\n",
    "    else:\n",
    "        print(f\"    Advertencia (Interacciones - Train): '{col1}' o '{col2}' no encontradas para crear interacción. Se omite.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2265d7a",
   "metadata": {},
   "source": [
    "# Probar modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fe00ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "027dc178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Evaluación de Modelos ---\n",
      "\n",
      "======================================================================\n",
      "--- Evaluando Conjunto de Datos: Base (Forma: (15000, 17)) ---\n",
      "======================================================================\n",
      "\n",
      "  --- Modelo: Árbol de Decisión ---\n",
      "    F1-Score Promedio (4 folds): 0.8996 (std: 0.0039)\n",
      "    F1-Scores por fold: [np.float64(0.8947), np.float64(0.901), np.float64(0.8974), np.float64(0.9052)]\n",
      "\n",
      "  --- Modelo: Naive Bayes Gaussiano ---\n",
      "    F1-Score Promedio (4 folds): 0.7225 (std: 0.0093)\n",
      "    F1-Scores por fold: [np.float64(0.7141), np.float64(0.7325), np.float64(0.7123), np.float64(0.7311)]\n",
      "\n",
      "  --- Modelo: Random Forest ---\n",
      "    F1-Score Promedio (4 folds): 0.9147 (std: 0.0059)\n",
      "    F1-Scores por fold: [np.float64(0.9071), np.float64(0.9161), np.float64(0.9121), np.float64(0.9233)]\n",
      "\n",
      "  --- Modelo: Gradient Boosting ---\n",
      "    F1-Score Promedio (4 folds): 0.9154 (std: 0.0063)\n",
      "    F1-Scores por fold: [np.float64(0.9048), np.float64(0.9189), np.float64(0.9208), np.float64(0.9173)]\n",
      "\n",
      "  --- Modelo: Bagging ---\n",
      "    F1-Score Promedio (4 folds): 0.9135 (std: 0.0036)\n",
      "    F1-Scores por fold: [np.float64(0.914), np.float64(0.9145), np.float64(0.9077), np.float64(0.9177)]\n",
      "\n",
      "======================================================================\n",
      "--- Evaluando Conjunto de Datos: Caracteristicas Reducidas (Forma: (15000, 16)) ---\n",
      "======================================================================\n",
      "\n",
      "  --- Modelo: Árbol de Decisión ---\n",
      "    F1-Score Promedio (4 folds): 0.9022 (std: 0.0041)\n",
      "    F1-Scores por fold: [np.float64(0.8996), np.float64(0.9006), np.float64(0.8992), np.float64(0.9093)]\n",
      "\n",
      "  --- Modelo: Naive Bayes Gaussiano ---\n",
      "    F1-Score Promedio (4 folds): 0.7223 (std: 0.0097)\n",
      "    F1-Scores por fold: [np.float64(0.7144), np.float64(0.7322), np.float64(0.7109), np.float64(0.7318)]\n",
      "\n",
      "  --- Modelo: Random Forest ---\n",
      "    F1-Score Promedio (4 folds): 0.9164 (std: 0.0079)\n",
      "    F1-Scores por fold: [np.float64(0.9068), np.float64(0.9213), np.float64(0.911), np.float64(0.9267)]\n",
      "\n",
      "  --- Modelo: Gradient Boosting ---\n",
      "    F1-Score Promedio (4 folds): 0.9149 (std: 0.0065)\n",
      "    F1-Scores por fold: [np.float64(0.9038), np.float64(0.9188), np.float64(0.9197), np.float64(0.9172)]\n",
      "\n",
      "  --- Modelo: Bagging ---\n",
      "    F1-Score Promedio (4 folds): 0.9190 (std: 0.0056)\n",
      "    F1-Scores por fold: [np.float64(0.9217), np.float64(0.9145), np.float64(0.9129), np.float64(0.9267)]\n",
      "\n",
      "======================================================================\n",
      "--- Evaluando Conjunto de Datos: Interaccion de Caracteristicas (Forma: (15000, 23)) ---\n",
      "======================================================================\n",
      "\n",
      "  --- Modelo: Árbol de Decisión ---\n",
      "    F1-Score Promedio (4 folds): 0.8932 (std: 0.0040)\n",
      "    F1-Scores por fold: [np.float64(0.8872), np.float64(0.8948), np.float64(0.8926), np.float64(0.8983)]\n",
      "\n",
      "  --- Modelo: Naive Bayes Gaussiano ---\n",
      "    F1-Score Promedio (4 folds): 0.6698 (std: 0.0104)\n",
      "    F1-Scores por fold: [np.float64(0.6566), np.float64(0.6761), np.float64(0.6634), np.float64(0.6831)]\n",
      "\n",
      "  --- Modelo: Random Forest ---\n",
      "    F1-Score Promedio (4 folds): 0.8876 (std: 0.0068)\n",
      "    F1-Scores por fold: [np.float64(0.8876), np.float64(0.8873), np.float64(0.8782), np.float64(0.8974)]\n",
      "\n",
      "  --- Modelo: Gradient Boosting ---\n",
      "    F1-Score Promedio (4 folds): 0.9138 (std: 0.0069)\n",
      "    F1-Scores por fold: [np.float64(0.902), np.float64(0.9198), np.float64(0.9157), np.float64(0.9176)]\n",
      "\n",
      "  --- Modelo: Bagging ---\n",
      "    F1-Score Promedio (4 folds): 0.9141 (std: 0.0049)\n",
      "    F1-Scores por fold: [np.float64(0.9167), np.float64(0.9197), np.float64(0.9065), np.float64(0.9134)]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "--- Tabla Resumen de F1-Score Promedio (clase positiva=1) ---\n",
      "======================================================================\n",
      "                                Árbol de Decisión  Naive Bayes Gaussiano  Random Forest  Gradient Boosting  Bagging\n",
      "Base                                       0.8996                 0.7225         0.9147             0.9154   0.9135\n",
      "Caracteristicas Reducidas                  0.9022                 0.7223         0.9164             0.9149   0.9190\n",
      "Interaccion de Caracteristicas             0.8932                 0.6698         0.8876             0.9138   0.9141\n",
      "\n",
      "¡Proceso de evaluación de modelos completado!\n"
     ]
    }
   ],
   "source": [
    "# --- Bucle de Entrenamiento y Evaluación de Modelos ---\n",
    "print(\"\\n--- Iniciando Evaluación de Modelos ---\")\n",
    "\n",
    "conjuntos_datos_a_evaluar = []\n",
    "\n",
    "if 'df_entrenamiento_base' in locals() and not df_entrenamiento_base.empty:\n",
    "    conjuntos_datos_a_evaluar.append({'nombre': 'Base', 'datos': df_entrenamiento_base})\n",
    "else:\n",
    "    print(\"Advertencia: 'df_entrenamiento_base' no está definido o está vacío. Se omitirá.\")\n",
    "\n",
    "if 'df_entrenamiento_reducido' in locals() and not df_entrenamiento_reducido.empty:\n",
    "    conjuntos_datos_a_evaluar.append({'nombre': 'Caracteristicas Reducidas', 'datos': df_entrenamiento_reducido})\n",
    "else:\n",
    "    print(\"Advertencia: 'df_entrenamiento_reducido' no está definido o está vacío. Se omitirá.\")\n",
    "\n",
    "if 'df_entrenamiento_interacciones' in locals() and not df_entrenamiento_interacciones.empty:\n",
    "    conjuntos_datos_a_evaluar.append({'nombre': 'Interaccion de Caracteristicas', 'datos': df_entrenamiento_interacciones})\n",
    "else:\n",
    "    print(\"Advertencia: 'df_entrenamiento_interacciones' no está definido o está vacío. Se omitirá.\")\n",
    "\n",
    "if not conjuntos_datos_a_evaluar:\n",
    "    print(\"ERROR CRÍTICO: No hay DataFrames válidos para evaluar. Deteniendo el script.\")\n",
    "else:\n",
    "    # Preparar lista de modelos\n",
    "    modelos_a_evaluar = [\n",
    "        ('Árbol de Decisión', DecisionTreeClassifier(random_state=42)), # Traducido\n",
    "        ('Naive Bayes Gaussiano', GaussianNB()), # Traducido\n",
    "        ('Random Forest', RandomForestClassifier(random_state=42, n_jobs=-1)),\n",
    "        ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "        ('Bagging', BaggingClassifier(random_state=42, n_jobs=-1))\n",
    "    ]\n",
    "\n",
    "    # Definir StratifiedKFold y el F1 scorer\n",
    "    # Asumimos que la clase positiva para F1-score es '1'.\n",
    "    evaluador_f1 = make_scorer(f1_score, pos_label=1, zero_division=0)\n",
    "    num_divisiones = 4 # Renombrado\n",
    "    kfold_estratificado = StratifiedKFold(n_splits=num_divisiones, shuffle=True, random_state=42) # Renombrado\n",
    "\n",
    "    resultados_completos = {} \n",
    "    resumen_f1_promedio = {} \n",
    "\n",
    "    for info_conjunto in conjuntos_datos_a_evaluar: # Renombrado\n",
    "        nombre_conjunto = info_conjunto['nombre'] # Renombrado\n",
    "        df_actual_entrenamiento = info_conjunto['datos'] # Renombrado\n",
    "        \n",
    "        print(f\"\\n======================================================================\")\n",
    "        print(f\"--- Evaluando Conjunto de Datos: {nombre_conjunto} (Forma: {df_actual_entrenamiento.shape}) ---\")\n",
    "        print(f\"======================================================================\")\n",
    "\n",
    "        if objetivo not in df_actual_entrenamiento.columns:\n",
    "            print(f\"  ERROR: La columna objetivo '{objetivo}' no se encuentra en '{nombre_conjunto}'. Omitiendo.\")\n",
    "            continue\n",
    "\n",
    "        X_entrenamiento = df_actual_entrenamiento.drop(columns=[objetivo]) # Renombrado\n",
    "        y_entrenamiento = df_actual_entrenamiento[objetivo] # Renombrado\n",
    "        \n",
    "        # Verificar columna objetivo\n",
    "        valores_unicos_objetivo = y_entrenamiento.unique() # Renombrado\n",
    "        if not pd.api.types.is_numeric_dtype(y_entrenamiento) or not all(val in [0, 1] for val in valores_unicos_objetivo if pd.notna(val)) or len(valores_unicos_objetivo) > 2 :\n",
    "            print(f\"  ADVERTENCIA: Columna objetivo '{objetivo}' en '{nombre_conjunto}' (Valores: {valores_unicos_objetivo[:5]}) no es binaria (0/1) o contiene NaNs.\")\n",
    "        \n",
    "        resumen_f1_promedio[nombre_conjunto] = {}\n",
    "        resultados_completos[nombre_conjunto] = {}\n",
    "\n",
    "        for nombre_modelo, instancia_modelo in modelos_a_evaluar: # Renombrado\n",
    "            print(f\"\\n  --- Modelo: {nombre_modelo} ---\")\n",
    "            if X_entrenamiento.empty:\n",
    "                print(f\"    Omitiendo {nombre_modelo} porque X_entrenamiento está vacío.\")\n",
    "                resumen_f1_promedio[nombre_conjunto][nombre_modelo] = np.nan\n",
    "                resultados_completos[nombre_conjunto][nombre_modelo] = {'f1_promedio': np.nan, 'desv_est_f1': np.nan, 'f1_por_fold': [], 'error': 'X_entrenamiento vacío'}\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                puntuaciones_cv_f1 = cross_val_score(instancia_modelo, X_entrenamiento, y_entrenamiento, cv=kfold_estratificado, scoring=evaluador_f1, n_jobs=-1) # Renombrado\n",
    "                \n",
    "                f1_promedio_modelo = np.mean(puntuaciones_cv_f1) # Renombrado\n",
    "                desv_est_f1_modelo = np.std(puntuaciones_cv_f1) # Renombrado\n",
    "                \n",
    "                resumen_f1_promedio[nombre_conjunto][nombre_modelo] = f1_promedio_modelo\n",
    "                resultados_completos[nombre_conjunto][nombre_modelo] = {'f1_promedio': f1_promedio_modelo, 'desv_est_f1': desv_est_f1_modelo, 'f1_por_fold': puntuaciones_cv_f1.tolist()}\n",
    "                \n",
    "                print(f\"    F1-Score Promedio ({num_divisiones} folds): {f1_promedio_modelo:.4f} (std: {desv_est_f1_modelo:.4f})\")\n",
    "                print(f\"    F1-Scores por fold: {[round(s, 4) for s in puntuaciones_cv_f1]}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR al entrenar/evaluar {nombre_modelo} en {nombre_conjunto}: {e}\")\n",
    "                resumen_f1_promedio[nombre_conjunto][nombre_modelo] = np.nan\n",
    "                resultados_completos[nombre_conjunto][nombre_modelo] = {'f1_promedio': np.nan, 'desv_est_f1': np.nan, 'f1_por_fold': [], 'error': str(e)}\n",
    "\n",
    "    # Imprimir tabla resumen\n",
    "    print(f\"\\n\\n======================================================================\")\n",
    "    print(f\"--- Tabla Resumen de F1-Score Promedio (clase positiva=1) ---\")\n",
    "    print(f\"======================================================================\")\n",
    "\n",
    "    if resumen_f1_promedio:\n",
    "        df_resumen = pd.DataFrame(resumen_f1_promedio).T # Renombrado\n",
    "        orden_modelos = [name for name, _ in modelos_a_evaluar] # Renombrado\n",
    "        columnas_existentes_modelos = [m for m in orden_modelos if m in df_resumen.columns] # Renombrado\n",
    "        if columnas_existentes_modelos:\n",
    "            df_resumen = df_resumen[columnas_existentes_modelos]\n",
    "        \n",
    "        print(df_resumen.to_string(float_format=\"%.4f\"))\n",
    "    else:\n",
    "        print(\"No se generaron resultados para el resumen.\")\n",
    "\n",
    "print(\"\\n¡Proceso de evaluación de modelos completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69617b42",
   "metadata": {},
   "source": [
    "## Funcion Predict Modelo\n",
    "Esta funcion, dado un modelo y una df hace un predict y lo guarda en su correspondiente csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96b472c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCSV(model, model_name, df_toPredict, df_name):\n",
    "    columns = ['id', 'fallo']\n",
    "    csv_file = f\"CSVModelos/{model_name}_{df_name}.csv\"\n",
    "    header = True\n",
    "\n",
    "    for i in range(0, len(df_toPredict), 500):\n",
    "        test_predict = model.predict(df_toPredict[i:i+500])\n",
    "        \n",
    "        indi = [j for j in range(i, i+500,1)]\n",
    "        valor = [test_predict[k] for k in range(500)]\n",
    "\n",
    "        results = pd.DataFrame(list(zip(indi,valor)), columns=columns)\n",
    "\n",
    "        results.to_csv(csv_file, mode='a', header=header, index=False)\n",
    "        header = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e41fa",
   "metadata": {},
   "source": [
    "## DECISIONTREE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7559a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictArbolDecision():\n",
    "    df_to_train = df_entrenamiento_reducido.copy()\n",
    "    df_toTest = df_prueba_reducido.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"ArbolDecision\",df_toTest,\"Reducido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81a0cd",
   "metadata": {},
   "source": [
    "## NAIVEBAYES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afac54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNaiveBayes():\n",
    "    df_to_train = df_entrenamiento_base.copy()\n",
    "    df_toTest = df_prueba_base.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"NaiveBayes\",df_toTest,\"Basico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263a810",
   "metadata": {},
   "source": [
    "## RANDOMFOREST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b64c26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRandomForest():\n",
    "    df_to_train = df_entrenamiento_reducido.copy()\n",
    "    df_toTest = df_prueba_reducido.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"RandomForest\",df_toTest,\"Reducido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628fde86",
   "metadata": {},
   "source": [
    "## GRADIENTBOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8290927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictGradientBoosting():\n",
    "    df_to_train = df_entrenamiento_base.copy()\n",
    "    df_toTest = df_prueba_base.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = GradientBoostingClassifier(random_state=42)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"GradientBoosting\",df_toTest,\"Basico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08206b80",
   "metadata": {},
   "source": [
    "## BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "103cf294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictBagging():\n",
    "    df_to_train = df_entrenamiento_reducido.copy()\n",
    "    df_toTest = df_prueba_reducido.copy()\n",
    "\n",
    "    X_entrenamiento = df_to_train.drop(columns=[objetivo]) \n",
    "    y_entrenamiento = df_to_train[objetivo] \n",
    "\n",
    "    model = BaggingClassifier(random_state=42, n_jobs=-1)\n",
    "    model.fit(X_entrenamiento,y_entrenamiento)\n",
    "\n",
    "\n",
    "    predictCSV(model,\"ArbolDecision\",df_toTest,\"Reducido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b31061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictArbolDecision()\n",
    "#predictNaiveBayes()\n",
    "#predictRandomForest()\n",
    "#predictGradientBoosting()\n",
    "#predictBagging()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNI312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
